{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Day039_yolov3_keras_HW","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CG77DrrB2CrU"},"source":["## 作業\n","該版本的 yolov3 實現邏輯主要寫在 `yolo.py` 中 `YOLO` 這個 class 的 `detect_image` ，其回傳已畫上檢測到的 bboxes 和物件類別的圖片。\n","\n","1. 請嘗試閱讀及盡量理解 `detect_image` 的程式碼片段\n","2. 請修改/模仿 `detect_image` 的寫法，使其回傳 bboxes 的信息、信心度及 bboxes 對應的類別\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQ0ZKKn1LhF0","executionInfo":{"status":"ok","timestamp":1629691759340,"user_tz":-480,"elapsed":50035,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"393e2903-71fe-44be-a93a-fba856f34c2f"},"source":["# h5py版本要是2.XX，否則會出現問題\n","# !pip uninstall h5py\n","# !pip install h5py==2.10.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found existing installation: h5py 2.10.0\n","Uninstalling h5py-2.10.0:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/h5py-2.10.0.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/h5py/*\n","Proceed (y/n)? n\n","Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCEP-DG0VxlV","executionInfo":{"status":"ok","timestamp":1629691759340,"user_tz":-480,"elapsed":16,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"ae3ef03c-ada4-4a8f-c0a2-045e125d1215"},"source":["%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow is already loaded. Please restart the runtime to change versions.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vELO-PTVxAtm","executionInfo":{"status":"ok","timestamp":1629691759341,"user_tz":-480,"elapsed":14,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"4d633f9c-24ea-4522-826b-96ae76b19ed1"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","# 下載基於 keras 的 yolov3 程式碼\n","%cd 'gdrive/My Drive'\n","!git clone https://github.com/qqwweee/keras-yolo3 # 如果之前已經下載過就可以註解掉\n","%cd keras-yolo3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","[Errno 2] No such file or directory: 'gdrive/My Drive'\n","/content/gdrive/My Drive/keras-yolo3\n","fatal: destination path 'keras-yolo3' already exists and is not an empty directory.\n","/content/gdrive/My Drive/keras-yolo3/keras-yolo3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Avxgh7T7yp2g","executionInfo":{"status":"ok","timestamp":1629691759342,"user_tz":-480,"elapsed":10,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"83f704ab-d992-4152-e425-afa2329867bc"},"source":["import os\n","import subprocess\n","if not os.path.exists(\"model_data/yolo.h5\"):\n","  # 下載 yolov3 的網路權重，並且把權重轉換為 keras 能夠讀取的格式\n","  print(\"Model doesn't exist, downloading...\")\n","  os.system(\"wget https://pjreddie.com/media/files/yolov3.weights\")\n","  print(\"Converting yolov3.weights to yolo.h5...\")\n","  os.system(\"python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\")\n","else:\n","  print(\"Model exist\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model exist\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MWPFl6dU1rjr","executionInfo":{"status":"ok","timestamp":1629691759740,"user_tz":-480,"elapsed":407,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"5c60e44f-0059-4c92-b4d2-d7bbd9873f96"},"source":["# 下載圖片範例，如果已經下載過就可以註解掉\n","!wget https://github.com/pjreddie/darknet/blob/master/data/dog.jpg?raw=true -O dog.jpg\n","# !wget https://github.com/pjreddie/darknet/blob/master/data/horses.jpg?raw=true -O horses.jpg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-08-23 04:09:19--  https://github.com/pjreddie/darknet/blob/master/data/dog.jpg?raw=true\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github.com/pjreddie/darknet/raw/master/data/dog.jpg [following]\n","--2021-08-23 04:09:19--  https://github.com/pjreddie/darknet/raw/master/data/dog.jpg\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/pjreddie/darknet/master/data/dog.jpg [following]\n","--2021-08-23 04:09:19--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/dog.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 163759 (160K) [image/jpeg]\n","Saving to: ‘dog.jpg’\n","\n","dog.jpg             100%[===================>] 159.92K  --.-KB/s    in 0.02s   \n","\n","2021-08-23 04:09:19 (6.95 MB/s) - ‘dog.jpg’ saved [163759/163759]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-vhfpWt92WZS"},"source":["# 將 yolo.py 所需要的套件載入\n","import colorsys\n","import os\n","import cv2\n","from timeit import default_timer as timer\n","\n","import numpy as np\n","from keras import backend as K\n","from keras.models import load_model\n","from keras.layers import Input\n","from PIL import Image, ImageFont, ImageDraw\n","\n","from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n","from yolo3.utils import letterbox_image\n","import os\n","from keras.utils import multi_gpu_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"i-AMDH1d4ESV"},"source":["# 定義 YOLO class\n","class YOLO(object):\n","    _defaults = {\n","        \"model_path\": 'model_data/yolo.h5',\n","        \"anchors_path\": 'model_data/yolo_anchors.txt',\n","        \"classes_path\": 'model_data/coco_classes.txt',\n","        \"score\" : 0.3,\n","        \"iou\" : 0.45,\n","        \"model_image_size\" : (416, 416),\n","        \"gpu_num\" : 1,\n","    }\n","\n","    @classmethod\n","    def get_defaults(cls, n):\n","        if n in cls._defaults:\n","            return cls._defaults[n]\n","        else:\n","            return \"Unrecognized attribute name '\" + n + \"'\"\n","\n","    def __init__(self, **kwargs):\n","        self.__dict__.update(self._defaults) # set up default values\n","        self.__dict__.update(kwargs) # and update with user overrides\n","        self.class_names = self._get_class()\n","        self.anchors = self._get_anchors()\n","        self.sess = K.get_session()\n","        self.boxes, self.scores, self.classes = self.generate()\n","\n","    def _get_class(self):\n","        classes_path = os.path.expanduser(self.classes_path)\n","        with open(classes_path) as f:\n","            class_names = f.readlines()\n","        class_names = [c.strip() for c in class_names]\n","        return class_names\n","\n","    def _get_anchors(self):\n","        anchors_path = os.path.expanduser(self.anchors_path)\n","        with open(anchors_path) as f:\n","            anchors = f.readline()\n","        anchors = [float(x) for x in anchors.split(',')]\n","        return np.array(anchors).reshape(-1, 2)\n","\n","    def generate(self):\n","        model_path = os.path.expanduser(self.model_path)\n","        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n","\n","        # Load model, or construct model and load weights.\n","        num_anchors = len(self.anchors)\n","        num_classes = len(self.class_names)\n","        is_tiny_version = num_anchors==6 # default setting\n","        try:\n","            self.yolo_model = load_model(model_path, compile=False)\n","        except:\n","            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n","                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n","            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n","        else:\n","            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n","                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n","                'Mismatch between model and given anchor and class sizes'\n","\n","        print('{} model, anchors, and classes loaded.'.format(model_path))\n","\n","        # Generate colors for drawing bounding boxes.\n","        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n","                      for x in range(len(self.class_names))]\n","        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","        self.colors = list(\n","            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n","                self.colors))\n","        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n","        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n","        np.random.seed(None)  # Reset seed to default.\n","\n","        # Generate output tensor targets for filtered bounding boxes.\n","        self.input_image_shape = K.placeholder(shape=(2, ))\n","        if self.gpu_num>=2:\n","            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n","        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n","                len(self.class_names), self.input_image_shape,\n","                score_threshold=self.score, iou_threshold=self.iou)\n","        return boxes, scores, classes\n","\n","    # 更改 detect_image 使得其回傳需要的信息\n","    def detect_image(self, image):\n","        start = timer()\n","\n","        if self.model_image_size != (None, None):\n","            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n","            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n","            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n","        else:\n","            new_image_size = (image.width - (image.width % 32),\n","                              image.height - (image.height % 32))\n","            boxed_image = letterbox_image(image, new_image_size)\n","        image_data = np.array(boxed_image, dtype='float32')\n","\n","        print(image_data.shape)\n","        image_data /= 255.\n","        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n","\n","        out_boxes, out_scores, out_classes = self.sess.run(\n","            [self.boxes, self.scores, self.classes],\n","            feed_dict={\n","                self.yolo_model.input: image_data,\n","                self.input_image_shape: [image.size[1], image.size[0]],\n","                K.learning_phase(): 0\n","            })\n","\n","        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n","\n","        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n","                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n","        thickness = (image.size[0] + image.size[1]) // 300\n","\n","        for i, c in reversed(list(enumerate(out_classes))):\n","            predicted_class = self.class_names[c]\n","            box = out_boxes[i]\n","            score = out_scores[i]\n","\n","            label = '{} {:.2f}'.format(predicted_class, score)\n","            draw = ImageDraw.Draw(image)\n","            label_size = draw.textsize(label, font)\n","\n","            top, left, bottom, right = box\n","            top = max(0, np.floor(top + 0.5).astype('int32'))\n","            left = max(0, np.floor(left + 0.5).astype('int32'))\n","            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n","            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n","            print(label, (left, top), (right, bottom))\n","\n","            if top - label_size[1] >= 0:\n","                text_origin = np.array([left, top - label_size[1]])\n","            else:\n","                text_origin = np.array([left, top + 1])\n","\n","            # My kingdom for a good redistributable image drawing library.\n","            for i in range(thickness):\n","                draw.rectangle(\n","                    [left + i, top + i, right - i, bottom - i],\n","                    outline=self.colors[c])\n","            draw.rectangle(\n","                [tuple(text_origin), tuple(text_origin + label_size)],\n","                fill=self.colors[c])\n","            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n","            del draw\n","\n","        end = timer()\n","        print(end - start)\n","        return image, out_boxes, out_scores, out_classes # Hint: 在這裡更改程式碼即可\n","\n","    def close_session(self):\n","        self.sess.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sncElkSw4l7c","executionInfo":{"status":"ok","timestamp":1629692922005,"user_tz":-480,"elapsed":18834,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"1af0c796-f615-45fc-9c8b-7acc956c7204"},"source":["yolo = YOLO() # 初始化 YOLO class"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model_data/yolo.h5 model, anchors, and classes loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lagEUwBwMB8j","executionInfo":{"status":"ok","timestamp":1629692985565,"user_tz":-480,"elapsed":1945,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"a41dd944-a41d-4b21-b2e8-cda82a59a34d"},"source":["image = Image.open(\"dog.jpg\")\n","if image is None:\n","  raise ValueError(\"Read image failed\")\n","r_image, out_boxes, out_scores, out_classes = yolo.detect_image(image)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(416, 416, 3)\n","Found 3 boxes for img\n","dog 0.99 (128, 224) (314, 537)\n","truck 0.91 (475, 85) (689, 170)\n","bicycle 0.99 (162, 119) (565, 441)\n","1.696051291999538\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mopkNPZ4P09D","executionInfo":{"status":"ok","timestamp":1629693072055,"user_tz":-480,"elapsed":228,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"8875cf37-a61c-4ff8-f206-e6648809b518"},"source":["r_image\n","print(\n","  out_boxes, # bboxes 座標訊息[top, left, bottom, right]\n","  out_scores, # 信心程度\n","  out_classes, # 類別\n","  sep=\"\\n\"\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[118.69406 162.05157 441.46826 564.93695]\n"," [ 85.18431 475.42786 170.2526  688.5249 ]\n"," [224.28874 128.1214  537.0223  313.8713 ]]\n","[0.9935903  0.9145597  0.98965937]\n","[ 1  7 16]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5wfTjn5kPzxl"},"source":[""],"execution_count":null,"outputs":[]}]}