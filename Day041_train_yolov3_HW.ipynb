{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Day41_train_yolov3_HW.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CG77DrrB2CrU"},"source":["## 作業\n","\n","1. 如何使用已經訓練好的模型？\n","2. 依照 https://github.com/qqwweee/keras-yolo3 的程式碼，請敘述，訓練模型時，資料集的格式是什麼？具體一點的說，要提供什麼格式的文件來描述資料集的圖片以及 bboxes 的信息呢？\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vqikl33WwzD","executionInfo":{"status":"ok","timestamp":1629774386362,"user_tz":-480,"elapsed":14995,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"8f002da1-3109-4718-c8c1-1db7d3e71bd2"},"source":["# h5py版本要是2.XX，否則會出現問題\n","!pip uninstall h5py\n","!pip install h5py==2.10.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Found existing installation: h5py 3.1.0\n","Uninstalling h5py-3.1.0:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/h5py-3.1.0.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/h5py.libs/libaec-9c9e97eb.so.0.0.10\n","    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5-00e8fae8.so.200.0.0\n","    /usr/local/lib/python3.7/dist-packages/h5py.libs/libhdf5_hl-383c339f.so.200.0.0\n","    /usr/local/lib/python3.7/dist-packages/h5py.libs/libsz-e7aa62f5.so.2.0.1\n","    /usr/local/lib/python3.7/dist-packages/h5py.libs/libz-eb09ad1d.so.1.2.3\n","    /usr/local/lib/python3.7/dist-packages/h5py/*\n","Proceed (y/n)? n\n","Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n","Installing collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCEP-DG0VxlV","executionInfo":{"status":"ok","timestamp":1629774391795,"user_tz":-480,"elapsed":5453,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"22f8f15a-41a5-4ad6-df1b-ffcebebcda06"},"source":["%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXT7SQe0KQxv","executionInfo":{"status":"ok","timestamp":1629774495297,"user_tz":-480,"elapsed":3934,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"882b3161-b0b5-47c5-8383-019b846d0324"},"source":["pip install keras==2.2.4 # 需要安裝 keras 2.2.4 的版本"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting keras==2.2.4\n","  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras==2.2.4) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.6.0\n","    Uninstalling keras-2.6.0:\n","      Successfully uninstalled keras-2.6.0\n","Successfully installed keras-2.2.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vELO-PTVxAtm","executionInfo":{"status":"ok","timestamp":1629774421019,"user_tz":-480,"elapsed":26165,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"80c04bda-d2c5-4674-b778-cf881db18da9"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","# 下載基於 keras 的 yolov3 程式碼\n","%cd 'gdrive/My Drive'\n","# !git clone https://github.com/qqwweee/keras-yolo3 # 如果之前已經下載過就可以註解掉\n","%cd keras-yolo3"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive\n","/content/gdrive/My Drive/keras-yolo3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"k0MyCUeRuARA","executionInfo":{"status":"ok","timestamp":1629774421879,"user_tz":-480,"elapsed":892,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}}},"source":["from PIL import Image\n","image = Image.open('dog.jpg') "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ooyy53TW5c0L","executionInfo":{"status":"ok","timestamp":1629774421881,"user_tz":-480,"elapsed":100,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"0bd0c8bd-a0af-4c4c-9683-02ec460780a1"},"source":["import os\n","if not os.path.exists(\"model_data/yolo.h5\"):\n","  # 下載 yolov3 的網路權重，並且把權重轉換為 keras 能夠讀取的格式\n","  print(\"Model doesn't exist, downloading...\")\n","  os.system(\"wget https://pjreddie.com/media/files/yolov3.weights\")\n","  print(\"Converting yolov3.weights to yolo.h5...\")\n","  os.system(\"python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\")\n","else:\n","  print(\"Model exist\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model exist\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gppcqjFV7SQa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629774421883,"user_tz":-480,"elapsed":76,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"e3df0d03-6ac0-45fb-a037-4fd6bc9c3016"},"source":["# 直接下載 VOC2007 的資料集作為範例\n","if not os.path.exists(\"VOCdevkit\"):\n","  os.system(\"wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\") # 下載 VOC 資料集\n","  os.system(\"tar xvf VOCtrainval_06-Nov-2007.tar\") # 解壓縮資料集，會花幾分鐘\n","else:\n","  print(\"data exists\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["data exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_EQD4kJN7_RR","executionInfo":{"status":"ok","timestamp":1629774421885,"user_tz":-480,"elapsed":68,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}}},"source":["if not os.path.exists(\"2007_train.txt\"): # 範例中訓練模型時所使用的，已經做好轉換的 annotation 檔名，增加這個檢查避免每次重新跑這段轉換的程式碼\n","  import xml.etree.ElementTree as ET # 載入能夠 Parser xml 文件的 library\n","  from os import getcwd\n","\n","  sets=[('2007', 'train'), ('2007', 'val')]\n","\n","  # Pascal VOC 的資料類別\n","  classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n","\n","  # 把 annotation 轉換訓練時需要的資料形態\n","  def convert_annotation(year, image_id, list_file):\n","      in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))\n","      tree=ET.parse(in_file)\n","      root = tree.getroot()\n","\n","      for obj in root.iter('object'):\n","          difficult = obj.find('difficult').text\n","          cls = obj.find('name').text\n","          if cls not in classes or int(difficult)==1:\n","              continue\n","          cls_id = classes.index(cls)\n","          xmlbox = obj.find('bndbox')\n","          b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n","          list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n","\n","  wd = \".\"\n","\n","  for year, image_set in sets:\n","      image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\n","      annotation_path = '%s_%s.txt'%(year, image_set)\n","      list_file = open(annotation_path, 'w')\n","      print(list_file)\n","      print(\"save annotation at %s\" % annotation_path)\n","      for image_id in image_ids[:100]: # 只處理 100 張圖片來做範例\n","          list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg'%(wd, year, image_id))\n","          convert_annotation(year, image_id, list_file)\n","          list_file.write('\\n')\n","      list_file.close()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"IITqb1HAVKt9","executionInfo":{"status":"ok","timestamp":1629774505642,"user_tz":-480,"elapsed":259,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}}},"source":["# 將 train.py 所需要的套件載入\n","import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n","from yolo3.utils import get_random_data"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzpcMXc3VjCT","executionInfo":{"status":"ok","timestamp":1629774510250,"user_tz":-480,"elapsed":1118,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}}},"source":["from train import get_classes, get_anchors, create_model, create_tiny_model, data_generator, data_generator_wrapper"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMEdFJ2QVlmK","executionInfo":{"status":"ok","timestamp":1629774512881,"user_tz":-480,"elapsed":14,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"6b0bf0a9-8e29-48d4-c841-cc5796e86617"},"source":["if not os.path.exists(\"model_data/yolo_weights.h5\"):\n","  print(\"Converting pretrained YOLOv3 weights for training\")\n","  os.system(\"python convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5\") \n","else:\n","  print(\"Pretrained weights exists\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Pretrained weights exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGbResoWWg79","executionInfo":{"status":"ok","timestamp":1629775178853,"user_tz":-480,"elapsed":654381,"user":{"displayName":"劉光智","photoUrl":"","userId":"17636341872413827911"}},"outputId":"9401aa0e-c18a-4776-c2c6-cc0fc588807c"},"source":["annotation_path = '2007_train.txt' # 轉換好格式的標註檔案\n","log_dir = 'logs/000/' # 訓練好的模型儲存的路徑\n","classes_path = 'model_data/voc_classes.txt'\n","anchors_path = 'model_data/yolo_anchors.txt'\n","class_names = get_classes(classes_path)\n","num_classes = len(class_names)\n","anchors = get_anchors(anchors_path)\n","\n","input_shape = (416,416) # multiple of 32, hw\n","\n","is_tiny_version = len(anchors)==6 # default setting\n","if is_tiny_version:\n","    model = create_tiny_model(input_shape, anchors, num_classes,\n","        freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n","else:\n","    model = create_model(input_shape, anchors, num_classes,\n","        freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n","\n","logging = TensorBoard(log_dir=log_dir)\n","checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","\n","# 分為 training 以及 validation\n","val_split = 0.1\n","with open(annotation_path) as f:\n","    lines = f.readlines()\n","np.random.seed(10101)\n","np.random.shuffle(lines)\n","np.random.seed(None)\n","num_val = int(len(lines)*val_split)\n","num_train = len(lines) - num_val\n","\n","# Train with frozen layers first, to get a stable loss.\n","# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n","# 一開始先 freeze YOLO 除了 output layer 以外的 darknet53 backbone 來 train\n","if True:\n","    model.compile(optimizer=Adam(lr=1e-3), loss={\n","        # use custom yolo_loss Lambda layer.\n","        'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","    batch_size = 16\n","    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","    # 模型利用 generator 產生的資料做訓練，強烈建議大家去閱讀及理解 data_generator_wrapper 在 train.py 中的實現\n","    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","            steps_per_epoch=max(1, num_train//batch_size),\n","            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","            validation_steps=max(1, num_val//batch_size),\n","            epochs=50,\n","            initial_epoch=0,\n","            callbacks=[logging, checkpoint])\n","    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n","\n","# Unfreeze and continue training, to fine-tune.\n","# Train longer if the result is not good.\n","if True:\n","    # 把所有 layer 都改為 trainable\n","    for i in range(len(model.layers)):\n","        model.layers[i].trainable = True\n","    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n","    print('Unfreeze all of the layers.')\n","\n","    batch_size = 16 # note that more GPU memory is required after unfreezing the body\n","    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","        steps_per_epoch=max(1, num_train//batch_size),\n","        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","        validation_steps=max(1, num_val//batch_size),\n","        epochs=100,\n","        initial_epoch=50,\n","        callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n","    model.save_weights(log_dir + 'trained_weights_final.h5')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","Create YOLOv3 model with 9 anchors and 20 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 75) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((75,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 75) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((75,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 75) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((75,) vs (255,)).\n","  weight_values[i].shape))\n"],"name":"stderr"},{"output_type":"stream","text":["Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3080: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Train on 90 samples, val on 10 samples, with batch size 16.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/50\n","5/5 [==============================] - 65s 13s/step - loss: 10058.5767 - val_loss: 7137.7495\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/50\n","5/5 [==============================] - 8s 2s/step - loss: 5910.7868 - val_loss: 4200.1108\n","Epoch 3/50\n","5/5 [==============================] - 6s 1s/step - loss: 3453.8174 - val_loss: 2471.5740\n","Epoch 4/50\n","5/5 [==============================] - 2s 451ms/step - loss: 2066.0037 - val_loss: 1513.6517\n","Epoch 5/50\n","5/5 [==============================] - 2s 457ms/step - loss: 1303.0352 - val_loss: 928.1257\n","Epoch 6/50\n","5/5 [==============================] - 3s 630ms/step - loss: 879.0911 - val_loss: 708.8652\n","Epoch 7/50\n","5/5 [==============================] - 6s 1s/step - loss: 636.7961 - val_loss: 505.5872\n","Epoch 8/50\n","5/5 [==============================] - 7s 1s/step - loss: 495.6570 - val_loss: 434.2435\n","Epoch 9/50\n","5/5 [==============================] - 6s 1s/step - loss: 410.6545 - val_loss: 371.8433\n","Epoch 10/50\n","5/5 [==============================] - 6s 1s/step - loss: 348.5193 - val_loss: 300.4054\n","Epoch 11/50\n","5/5 [==============================] - 7s 1s/step - loss: 303.7399 - val_loss: 255.7249\n","Epoch 12/50\n","5/5 [==============================] - 6s 1s/step - loss: 274.7698 - val_loss: 268.4019\n","Epoch 13/50\n","5/5 [==============================] - 6s 1s/step - loss: 248.4770 - val_loss: 226.9383\n","Epoch 14/50\n","5/5 [==============================] - 7s 1s/step - loss: 231.4885 - val_loss: 194.2335\n","Epoch 15/50\n","5/5 [==============================] - 6s 1s/step - loss: 222.1532 - val_loss: 220.3474\n","Epoch 16/50\n","5/5 [==============================] - 6s 1s/step - loss: 196.9505 - val_loss: 216.0270\n","Epoch 17/50\n","5/5 [==============================] - 7s 1s/step - loss: 194.8477 - val_loss: 167.0290\n","Epoch 18/50\n","5/5 [==============================] - 6s 1s/step - loss: 184.6472 - val_loss: 180.7217\n","Epoch 19/50\n","5/5 [==============================] - 6s 1s/step - loss: 171.4036 - val_loss: 178.8412\n","Epoch 20/50\n","5/5 [==============================] - 7s 1s/step - loss: 163.4795 - val_loss: 154.4167\n","Epoch 21/50\n","5/5 [==============================] - 6s 1s/step - loss: 152.3637 - val_loss: 155.3508\n","Epoch 22/50\n","5/5 [==============================] - 6s 1s/step - loss: 149.8114 - val_loss: 162.6287\n","Epoch 23/50\n","5/5 [==============================] - 7s 1s/step - loss: 142.7357 - val_loss: 116.6200\n","Epoch 24/50\n","5/5 [==============================] - 6s 1s/step - loss: 141.2065 - val_loss: 144.4456\n","Epoch 25/50\n","5/5 [==============================] - 6s 1s/step - loss: 131.8326 - val_loss: 134.3754\n","Epoch 26/50\n","5/5 [==============================] - 7s 1s/step - loss: 128.1094 - val_loss: 129.0747\n","Epoch 27/50\n","5/5 [==============================] - 6s 1s/step - loss: 121.8903 - val_loss: 120.3963\n","Epoch 28/50\n","5/5 [==============================] - 6s 1s/step - loss: 115.8415 - val_loss: 110.8894\n","Epoch 29/50\n","5/5 [==============================] - 7s 1s/step - loss: 116.9455 - val_loss: 100.9564\n","Epoch 30/50\n","5/5 [==============================] - 6s 1s/step - loss: 112.9124 - val_loss: 127.2104\n","Epoch 31/50\n","5/5 [==============================] - 6s 1s/step - loss: 111.1043 - val_loss: 110.4656\n","Epoch 32/50\n","5/5 [==============================] - 6s 1s/step - loss: 105.7284 - val_loss: 111.2757\n","Epoch 33/50\n","5/5 [==============================] - 6s 1s/step - loss: 104.6897 - val_loss: 106.1281\n","Epoch 34/50\n","5/5 [==============================] - 6s 1s/step - loss: 101.8634 - val_loss: 90.6494\n","Epoch 35/50\n","5/5 [==============================] - 7s 1s/step - loss: 96.5096 - val_loss: 98.2913\n","Epoch 36/50\n","5/5 [==============================] - 6s 1s/step - loss: 93.1110 - val_loss: 100.4822\n","Epoch 37/50\n","5/5 [==============================] - 6s 1s/step - loss: 92.9781 - val_loss: 85.2034\n","Epoch 38/50\n","5/5 [==============================] - 7s 1s/step - loss: 90.4581 - val_loss: 104.4675\n","Epoch 39/50\n","5/5 [==============================] - 6s 1s/step - loss: 89.2222 - val_loss: 88.6921\n","Epoch 40/50\n","5/5 [==============================] - 6s 1s/step - loss: 86.3013 - val_loss: 89.4501\n","Epoch 41/50\n","5/5 [==============================] - 7s 1s/step - loss: 84.1551 - val_loss: 89.5661\n","Epoch 42/50\n","5/5 [==============================] - 6s 1s/step - loss: 85.4515 - val_loss: 83.6327\n","Epoch 43/50\n","5/5 [==============================] - 6s 1s/step - loss: 81.1082 - val_loss: 90.7563\n","Epoch 44/50\n","5/5 [==============================] - 7s 1s/step - loss: 78.9887 - val_loss: 81.5057\n","Epoch 45/50\n","5/5 [==============================] - 6s 1s/step - loss: 79.3673 - val_loss: 88.3222\n","Epoch 46/50\n","5/5 [==============================] - 6s 1s/step - loss: 76.0730 - val_loss: 76.9965\n","Epoch 47/50\n","5/5 [==============================] - 6s 1s/step - loss: 75.4227 - val_loss: 83.4840\n","Epoch 48/50\n","5/5 [==============================] - 6s 1s/step - loss: 75.8381 - val_loss: 76.0831\n","Epoch 49/50\n","5/5 [==============================] - 6s 1s/step - loss: 72.6517 - val_loss: 78.2171\n","Epoch 50/50\n","5/5 [==============================] - 7s 1s/step - loss: 69.5784 - val_loss: 74.2441\n","Unfreeze all of the layers.\n","Train on 90 samples, val on 10 samples, with batch size 16.\n","Epoch 51/100\n","5/5 [==============================] - 27s 5s/step - loss: 50.5458 - val_loss: 65.5549\n","Epoch 52/100\n","5/5 [==============================] - 6s 1s/step - loss: 40.8310 - val_loss: 53.7944\n","Epoch 53/100\n","5/5 [==============================] - 6s 1s/step - loss: 34.5233 - val_loss: 45.7600\n","Epoch 54/100\n","5/5 [==============================] - 6s 1s/step - loss: 32.1390 - val_loss: 40.1366\n","Epoch 55/100\n","5/5 [==============================] - 6s 1s/step - loss: 31.4632 - val_loss: 40.8080\n","Epoch 56/100\n","5/5 [==============================] - 8s 2s/step - loss: 29.1285 - val_loss: 41.0099\n","Epoch 57/100\n","5/5 [==============================] - 8s 2s/step - loss: 29.9754 - val_loss: 33.2598\n","Epoch 58/100\n","5/5 [==============================] - 7s 1s/step - loss: 27.6832 - val_loss: 41.2889\n","Epoch 59/100\n","5/5 [==============================] - 8s 2s/step - loss: 27.0506 - val_loss: 38.6442\n","Epoch 60/100\n","5/5 [==============================] - 8s 2s/step - loss: 26.5870 - val_loss: 34.2738\n","\n","Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n","Epoch 61/100\n","5/5 [==============================] - 6s 1s/step - loss: 24.8141 - val_loss: 29.6303\n","Epoch 62/100\n","5/5 [==============================] - 8s 2s/step - loss: 25.1340 - val_loss: 39.6926\n","Epoch 63/100\n","5/5 [==============================] - 8s 2s/step - loss: 25.8420 - val_loss: 32.6969\n","Epoch 64/100\n","5/5 [==============================] - 7s 1s/step - loss: 26.9228 - val_loss: 30.1777\n","\n","Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n","Epoch 65/100\n","5/5 [==============================] - 8s 2s/step - loss: 24.9835 - val_loss: 37.1098\n","Epoch 66/100\n","5/5 [==============================] - 8s 2s/step - loss: 24.7262 - val_loss: 34.4042\n","Epoch 67/100\n","5/5 [==============================] - 8s 2s/step - loss: 24.9018 - val_loss: 35.2922\n","\n","Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n","Epoch 68/100\n","5/5 [==============================] - 8s 2s/step - loss: 25.9116 - val_loss: 34.2617\n","Epoch 69/100\n","5/5 [==============================] - 7s 1s/step - loss: 25.9610 - val_loss: 30.2256\n","Epoch 70/100\n","5/5 [==============================] - 7s 1s/step - loss: 25.6456 - val_loss: 40.8793\n","\n","Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n","Epoch 71/100\n","5/5 [==============================] - 8s 2s/step - loss: 23.6102 - val_loss: 31.7238\n","Epoch 00071: early stopping\n"],"name":"stdout"}]}]}